{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12838082,"sourceType":"datasetVersion","datasetId":8119519}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n\n\n!pip install lime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:18:18.436925Z","iopub.execute_input":"2025-08-22T16:18:18.437143Z","iopub.status.idle":"2025-08-22T16:19:47.804483Z","shell.execute_reply.started":"2025-08-22T16:18:18.437126Z","shell.execute_reply":"2025-08-22T16:19:47.803762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.transforms import ToTensor\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenCAM, AblationCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom lime import lime_image\nimport zipfile\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:20:16.275960Z","iopub.execute_input":"2025-08-22T16:20:16.276226Z","iopub.status.idle":"2025-08-22T16:20:24.359944Z","shell.execute_reply.started":"2025-08-22T16:20:16.276196Z","shell.execute_reply":"2025-08-22T16:20:24.359365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = datasets.ImageFolder(root=\"/kaggle/input/bangladeshi-mango-leaf1/Image Dataset of Bangladeshi Mango Leaf/Root/Root/Original\", transform=transform_train)\nclass_names = dataset.classes\nnum_classes = len(class_names)\n\nprint(\"Classes found:\", class_names)\nprint(\"Number of classes:\", num_classes)\n\n\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.2 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\nval_dataset.dataset.transform = transform_test\ntest_dataset.dataset.transform = transform_test\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:21:23.218228Z","iopub.execute_input":"2025-08-22T16:21:23.218669Z","iopub.status.idle":"2025-08-22T16:21:24.068164Z","shell.execute_reply.started":"2025-08-22T16:21:23.218645Z","shell.execute_reply":"2025-08-22T16:21:24.067587Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Example Images for Each Class","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, num_classes, figsize=(15, 5))\ndisplayed_classes = {class_name: False for class_name in class_names}\n\nfor images, labels in train_loader:\n    for img, label in zip(images, labels):\n        class_name = class_names[label]\n        if not displayed_classes[class_name]:\n            img = img.permute(1, 2, 0).numpy()\n            img = (img * 0.5) + 0.5  # unnormalize\n            axs[label].imshow(np.clip(img, 0, 1))\n            axs[label].set_title(class_name)\n            axs[label].axis('off')\n            displayed_classes[class_name] = True\n\n        if all(displayed_classes.values()):\n            break\n    if all(displayed_classes.values()):\n        break\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:21:53.693110Z","iopub.execute_input":"2025-08-22T16:21:53.693757Z","iopub.status.idle":"2025-08-22T16:21:54.408736Z","shell.execute_reply.started":"2025-08-22T16:21:53.693727Z","shell.execute_reply":"2025-08-22T16:21:54.407946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define a Custom CNN Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomCNN, self).__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  \n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2),  \n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),  \n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1, 1))  \n        )\n\n        self.classifier = nn.Sequential(\n            nn.Flatten(),  \n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:22:41.050937Z","iopub.execute_input":"2025-08-22T16:22:41.051634Z","iopub.status.idle":"2025-08-22T16:22:41.057963Z","shell.execute_reply.started":"2025-08-22T16:22:41.051606Z","shell.execute_reply":"2025-08-22T16:22:41.057287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n\n    def __init__(self, patience=5):\n\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = np.inf\n\n    def check_early_stop(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:23:41.706529Z","iopub.execute_input":"2025-08-22T16:23:41.707106Z","iopub.status.idle":"2025-08-22T16:23:41.711653Z","shell.execute_reply.started":"2025-08-22T16:23:41.707079Z","shell.execute_reply":"2025-08-22T16:23:41.710925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model and Plot Loss Curves","metadata":{}},{"cell_type":"markdown","source":"# Training using Custom Model (Slow Without AMP)","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\nfrom tqdm import tqdm\n\nnum_epochs = 50\n\nmodel = CustomCNN(num_classes=len(class_names)).to('cuda')  \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nearly_stopping = EarlyStopping(patience=5)\n\ntrain_losses, val_losses = [], []\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()\n    train_loss = 0\n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  \n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  \n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:24:29.380614Z","iopub.execute_input":"2025-08-22T16:24:29.381162Z","iopub.status.idle":"2025-08-22T16:25:57.476343Z","shell.execute_reply.started":"2025-08-22T16:24:29.381128Z","shell.execute_reply":"2025-08-22T16:25:57.475614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a path for saving the model\n\nmodel_save_path = \"custom_cnn_model.pth\"  \n\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:26:28.652952Z","iopub.execute_input":"2025-08-22T16:26:28.653232Z","iopub.status.idle":"2025-08-22T16:26:28.669537Z","shell.execute_reply.started":"2025-08-22T16:26:28.653208Z","shell.execute_reply":"2025-08-22T16:26:28.669004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:26:51.684873Z","iopub.execute_input":"2025-08-22T16:26:51.685148Z","iopub.status.idle":"2025-08-22T16:26:51.863623Z","shell.execute_reply.started":"2025-08-22T16:26:51.685126Z","shell.execute_reply":"2025-08-22T16:26:51.862964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation and Metrics Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  \n    for images, labels in test_loader:\n        \n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        outputs = model(images)\n\n        _, predicted = torch.max(outputs, 1)\n\n        all_preds.extend(predicted.cpu().numpy())  \n        all_labels.extend(labels.cpu().numpy())    \n\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:27:53.753105Z","iopub.execute_input":"2025-08-22T16:27:53.753392Z","iopub.status.idle":"2025-08-22T16:27:54.514773Z","shell.execute_reply.started":"2025-08-22T16:27:53.753370Z","shell.execute_reply":"2025-08-22T16:27:54.514135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XAI - Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM","metadata":{}},{"cell_type":"code","source":"\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n\nmodel = CustomCNN(num_classes=num_classes).to('cuda')\nmodel.load_state_dict(torch.load(\"custom_cnn_model.pth\"))\nmodel.eval()\n\nsample_idx = 0  \nsample_image, true_label = test_dataset[sample_idx]\nsample_image = sample_image.unsqueeze(0).to('cuda')  \n\noriginal_image_np = sample_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\noriginal_image_np = (original_image_np * 0.5) + 0.5  # Unnormalize\noriginal_image_np = np.clip(original_image_np, 0, 1)\n\ntarget_layers = [model.features[-4]]  \n\ngradcam = GradCAM(model=model, target_layers=target_layers)\ngradcam_plus_plus = GradCAMPlusPlus(model=model, target_layers=target_layers)\neigen_cam = EigenCAM(model=model, target_layers=target_layers)\nablation_cam = AblationCAM(model=model, target_layers=target_layers)\n\nwith torch.no_grad():\n    outputs = model(sample_image)\n    predicted_class = outputs.argmax().item()\n    predicted_class_name = class_names[predicted_class]\n    true_class_name = class_names[true_label]\n\ntarget = [ClassifierOutputTarget(predicted_class)]\n\ngradcam_heatmap = gradcam(input_tensor=sample_image, targets=target)[0]\ngradcam_pp_heatmap = gradcam_plus_plus(input_tensor=sample_image, targets=target)[0]\neigen_cam_heatmap = eigen_cam(input_tensor=sample_image, targets=target)[0]\nablation_cam_heatmap = ablation_cam(input_tensor=sample_image, targets=target)[0]\n\ngradcam_result = show_cam_on_image(original_image_np, gradcam_heatmap, use_rgb=True)\ngradcam_pp_result = show_cam_on_image(original_image_np, gradcam_pp_heatmap, use_rgb=True)\neigen_cam_result = show_cam_on_image(original_image_np, eigen_cam_heatmap, use_rgb=True)\nablation_cam_result = show_cam_on_image(original_image_np, ablation_cam_heatmap, use_rgb=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:31:52.563404Z","iopub.execute_input":"2025-08-22T16:31:52.563725Z","iopub.status.idle":"2025-08-22T16:31:53.251161Z","shell.execute_reply.started":"2025-08-22T16:31:52.563702Z","shell.execute_reply":"2025-08-22T16:31:53.250595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the results\nplt.figure(figsize=(20, 5))\nplt.subplot(1, 5, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(True: {true_class_name}, Pred: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 2)\nplt.imshow(gradcam_result)\nplt.title(f\"Grad-CAM\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 3)\nplt.imshow(gradcam_pp_result)\nplt.title(f\"Grad-CAM++\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 4)\nplt.imshow(eigen_cam_result)\nplt.title(f\"Eigen-CAM\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 5)\nplt.imshow(ablation_cam_result)\nplt.title(f\"Ablation-CAM\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:31:59.337409Z","iopub.execute_input":"2025-08-22T16:31:59.338335Z","iopub.status.idle":"2025-08-22T16:31:59.947349Z","shell.execute_reply.started":"2025-08-22T16:31:59.338303Z","shell.execute_reply":"2025-08-22T16:31:59.946626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LIME","metadata":{}},{"cell_type":"code","source":"\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nfrom PIL import Image\n\ndef batch_predict(images):\n    model.eval()\n    \n    batch = torch.stack([\n        transform_test(Image.fromarray((image * 255).astype(np.uint8))) \n        for image in images\n    ], dim=0).to('cuda')\n    \n    with torch.no_grad():\n        logits = model(batch)\n    \n    return torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n\nexplainer = lime_image.LimeImageExplainer()\n\nlime_explanation = explainer.explain_instance(\n    original_image_np,  \n    batch_predict,      \n    top_labels=1,      \n    hide_color=0,\n    num_samples=100    \n)\n\nlime_image, lime_mask = lime_explanation.get_image_and_mask(\n    label=predicted_class,\n    positive_only=True,\n    hide_rest=False,\n    num_features=10,\n    min_weight=0.01\n)\nlime_image = mark_boundaries(lime_image, lime_mask)\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(True: {true_class_name}, Pred: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(lime_image)\nplt.title(f\"LIME Explanation\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T16:35:15.872934Z","iopub.execute_input":"2025-08-22T16:35:15.873541Z","iopub.status.idle":"2025-08-22T16:35:17.483807Z","shell.execute_reply.started":"2025-08-22T16:35:15.873513Z","shell.execute_reply":"2025-08-22T16:35:17.483111Z"}},"outputs":[],"execution_count":null}]}