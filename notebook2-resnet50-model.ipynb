{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12829965,"sourceType":"datasetVersion","datasetId":8113999}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git\n\n\n!pip install lime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:04:54.528369Z","iopub.execute_input":"2025-08-21T18:04:54.528621Z","iopub.status.idle":"2025-08-21T18:06:33.541860Z","shell.execute_reply.started":"2025-08-21T18:04:54.528602Z","shell.execute_reply":"2025-08-21T18:06:33.541161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.transforms import ToTensor\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom pytorch_grad_cam import GradCAM, GradCAMPlusPlus, EigenCAM, AblationCAM\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom lime import lime_image\nimport zipfile\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:07:53.302529Z","iopub.execute_input":"2025-08-21T18:07:53.302810Z","iopub.status.idle":"2025-08-21T18:08:04.668825Z","shell.execute_reply.started":"2025-08-21T18:07:53.302780Z","shell.execute_reply":"2025-08-21T18:08:04.668055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\ntransform_train = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ndataset = datasets.ImageFolder(root=\"/kaggle/input/bangladeshi-mango-leaf2/Image Dataset of Bangladeshi Mango Leaf/Root/Root/Original\", transform=transform_train)\nclass_names = dataset.classes\nnum_classes = len(class_names)\n\nprint(\"Classes found:\", class_names)\nprint(\"Number of classes:\", num_classes)\n\n\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.2 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\nval_dataset.dataset.transform = transform_test\ntest_dataset.dataset.transform = transform_test\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:09:01.939685Z","iopub.execute_input":"2025-08-21T18:09:01.940674Z","iopub.status.idle":"2025-08-21T18:09:03.935118Z","shell.execute_reply.started":"2025-08-21T18:09:01.940644Z","shell.execute_reply":"2025-08-21T18:09:03.934320Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Example Images for Each Class","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, num_classes, figsize=(15, 5))\ndisplayed_classes = {class_name: False for class_name in class_names}\n\nfor images, labels in train_loader:\n    for img, label in zip(images, labels):\n        class_name = class_names[label]\n        if not displayed_classes[class_name]:\n            img = img.permute(1, 2, 0).numpy()\n            img = (img * 0.5) + 0.5  # unnormalize\n            axs[label].imshow(np.clip(img, 0, 1))\n            axs[label].set_title(class_name)\n            axs[label].axis('off')\n            displayed_classes[class_name] = True\n\n        if all(displayed_classes.values()):\n            break\n    if all(displayed_classes.values()):\n        break\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:09:43.864529Z","iopub.execute_input":"2025-08-21T18:09:43.864825Z","iopub.status.idle":"2025-08-21T18:09:44.777196Z","shell.execute_reply.started":"2025-08-21T18:09:43.864804Z","shell.execute_reply":"2025-08-21T18:09:44.776365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Models","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision import models\n\ndef get_transfer_model(model_name, num_classes):\n    if model_name == \"vgg16\":\n        model = models.vgg16(pretrained=True)\n        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n\n    elif model_name == \"mobilenet_v2\":\n        model = models.mobilenet_v2(pretrained=True)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n\n    elif model_name == \"efficientnet_b0\":\n        model = models.efficientnet_b0(pretrained=True)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n\n    elif model_name == \"densenet121\":\n        model = models.densenet121(pretrained=True)\n        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n\n    elif model_name == \"inception_v3\":\n        model = models.inception_v3(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n\n    elif model_name == \"resnet50\":\n        model = models.resnet50(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)  \n\n    else:\n        raise ValueError(f\"Model '{model_name}' not supported. Choose from vgg16, mobilenet_v2, efficientnet_b0, densenet121, inception_v3, resnet50.\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:10:54.711325Z","iopub.execute_input":"2025-08-21T18:10:54.711611Z","iopub.status.idle":"2025-08-21T18:10:54.718121Z","shell.execute_reply.started":"2025-08-21T18:10:54.711579Z","shell.execute_reply":"2025-08-21T18:10:54.717451Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n\n    def __init__(self, patience=5):\n\n        self.patience = patience\n        self.counter = 0\n        self.best_loss = np.inf\n\n    def check_early_stop(self, val_loss):\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:11:25.411658Z","iopub.execute_input":"2025-08-21T18:11:25.411931Z","iopub.status.idle":"2025-08-21T18:11:25.416640Z","shell.execute_reply.started":"2025-08-21T18:11:25.411910Z","shell.execute_reply":"2025-08-21T18:11:25.415978Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Example using ResNet50","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm  \nfrom torch.cuda.amp import autocast, GradScaler  \n\nnum_epochs = 50  \n\nmodel = get_transfer_model('resnet50', num_classes).to('cuda')\ncriterion = nn.CrossEntropyLoss()  \n\noptimizer = optim.Adam(model.parameters(), lr=0.001)  \n\nearly_stopping = EarlyStopping(patience=5)  \n\ntrain_losses, val_losses = [], []  \n\nscaler = GradScaler()\n\nfor epoch in range(num_epochs):\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    model.train()  \n    train_loss = 0  \n    \n    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        images, labels = images.to('cuda'), labels.to('cuda')  \n\n        optimizer.zero_grad() \n\n        with autocast():  \n            outputs = model(images)  \n            loss = criterion(outputs, labels)  \n\n        scaler.scale(loss).backward()  \n        scaler.step(optimizer)  \n        scaler.update()  \n        train_loss += loss.item()  \n\n    model.eval()  \n    val_loss = 0  \n    with torch.no_grad():  \n        \n        for images, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n            images, labels = images.to('cuda'), labels.to('cuda')  \n            with autocast():  \n                outputs = model(images)  \n                loss = criterion(outputs, labels)  \n            val_loss += loss.item()  \n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n\n    if early_stopping.check_early_stop(avg_val_loss):\n        print(\"Early stopping triggered.\")\n        break\n\n\n\n# Save the model\ntorch.save(model.state_dict(), 'transfer_learning_resnet50.pth')\nprint(\"Model saved as 'transfer_learning_resnet50.pth'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:12:15.262279Z","iopub.execute_input":"2025-08-21T18:12:15.262954Z","iopub.status.idle":"2025-08-21T18:14:20.902121Z","shell.execute_reply.started":"2025-08-21T18:12:15.262925Z","shell.execute_reply":"2025-08-21T18:14:20.901442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting loss curves\n\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title(\"Training and Validation Loss for ResNet-50\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:14:42.381257Z","iopub.execute_input":"2025-08-21T18:14:42.381797Z","iopub.status.idle":"2025-08-21T18:14:42.546414Z","shell.execute_reply.started":"2025-08-21T18:14:42.381772Z","shell.execute_reply":"2025-08-21T18:14:42.545757Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation and Metrics Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  \n    for images, labels in test_loader:\n        \n        images, labels = images.to('cuda'), labels.to('cuda')\n\n        outputs = model(images)\n\n        _, predicted = torch.max(outputs, 1)\n\n        all_preds.extend(predicted.cpu().numpy())  \n        all_labels.extend(labels.cpu().numpy())    \n\naccuracy = accuracy_score(all_labels, all_preds)\nprecision = precision_score(all_labels, all_preds, average='weighted')\nrecall = recall_score(all_labels, all_preds, average='weighted')\nf1 = f1_score(all_labels, all_preds, average='weighted')\n\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:15:39.615931Z","iopub.execute_input":"2025-08-21T18:15:39.616275Z","iopub.status.idle":"2025-08-21T18:15:40.807269Z","shell.execute_reply.started":"2025-08-21T18:15:39.616250Z","shell.execute_reply":"2025-08-21T18:15:40.806612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XAI - Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM","metadata":{}},{"cell_type":"code","source":"from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n\ndef get_transfer_model(model_name, num_classes):\n    if model_name == \"resnet50\":\n        model = models.resnet50(pretrained=True)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    else:\n        raise ValueError(f\"Model '{model_name}' not supported.\")\n    return model\n\nmodel = get_transfer_model('resnet50', num_classes).to('cuda')\nmodel.load_state_dict(torch.load('transfer_learning_resnet50.pth'))\nmodel.eval()\n\nsample_idx = 0  \nsample_image, true_label = test_dataset[sample_idx]\nsample_image = sample_image.unsqueeze(0).to('cuda')  \n\noriginal_image_np = sample_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\noriginal_image_np = (original_image_np * 0.5) + 0.5  \noriginal_image_np = np.clip(original_image_np, 0, 1)\n\ntarget_layers = [model.layer4[-1]]  \n\ngradcam = GradCAM(model=model, target_layers=target_layers)\ngradcam_plus_plus = GradCAMPlusPlus(model=model, target_layers=target_layers)\neigen_cam = EigenCAM(model=model, target_layers=target_layers)\nablation_cam = AblationCAM(model=model, target_layers=target_layers)\n\nwith torch.no_grad():\n    outputs = model(sample_image)\n    predicted_class = outputs.argmax().item()\n    predicted_class_name = class_names[predicted_class]\n    true_class_name = class_names[true_label]\n\ntarget = [ClassifierOutputTarget(predicted_class)]\n\ngradcam_heatmap = gradcam(input_tensor=sample_image, targets=target)[0]\ngradcam_pp_heatmap = gradcam_plus_plus(input_tensor=sample_image, targets=target)[0]\neigen_cam_heatmap = eigen_cam(input_tensor=sample_image, targets=target)[0]\nablation_cam_heatmap = ablation_cam(input_tensor=sample_image, targets=target)[0]\n\ngradcam_result = show_cam_on_image(original_image_np, gradcam_heatmap, use_rgb=True)\ngradcam_pp_result = show_cam_on_image(original_image_np, gradcam_pp_heatmap, use_rgb=True)\neigen_cam_result = show_cam_on_image(original_image_np, eigen_cam_heatmap, use_rgb=True)\nablation_cam_result = show_cam_on_image(original_image_np, ablation_cam_heatmap, use_rgb=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:25:10.609600Z","iopub.execute_input":"2025-08-21T18:25:10.610355Z","iopub.status.idle":"2025-08-21T18:25:17.843811Z","shell.execute_reply.started":"2025-08-21T18:25:10.610330Z","shell.execute_reply":"2025-08-21T18:25:17.843033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the results\nplt.figure(figsize=(20, 5))\nplt.subplot(1, 5, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(True: {true_class_name}, Pred: {predicted_class_name})\", fontsize=10)\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 2)\nplt.imshow(gradcam_result)\nplt.title(f\"Grad-CAM\\n(Predicted: {predicted_class_name})\", fontsize=10)\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 3)\nplt.imshow(gradcam_pp_result)\nplt.title(f\"Grad-CAM++\\n(Predicted: {predicted_class_name})\", fontsize=10)\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 4)\nplt.imshow(eigen_cam_result)\nplt.title(f\"Eigen-CAM\\n(Predicted: {predicted_class_name})\", fontsize=10)\nplt.axis(\"off\")\n\nplt.subplot(1, 5, 5)\nplt.imshow(ablation_cam_result)\nplt.title(f\"Ablation-CAM\\n(Predicted: {predicted_class_name})\", fontsize=10)\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:25:47.635478Z","iopub.execute_input":"2025-08-21T18:25:47.636182Z","iopub.status.idle":"2025-08-21T18:25:48.313808Z","shell.execute_reply.started":"2025-08-21T18:25:47.636157Z","shell.execute_reply":"2025-08-21T18:25:48.313174Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LIME","metadata":{}},{"cell_type":"code","source":"from lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nfrom PIL import Image\n\ndef batch_predict(images):\n    model.eval()\n    \n    batch = torch.stack([\n        transform_test(Image.fromarray((image * 255).astype(np.uint8))) \n        for image in images\n    ], dim=0).to('cuda')\n    \n    with torch.no_grad():\n        logits = model(batch)\n    \n    return torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n\nexplainer = lime_image.LimeImageExplainer()\n\nlime_explanation = explainer.explain_instance(\n    original_image_np,  \n    batch_predict,\n    top_labels=1,       \n    hide_color=0,\n    num_samples=100    \n)\n\nlime_image, lime_mask = lime_explanation.get_image_and_mask(\n    label=predicted_class,\n    positive_only=True,\n    hide_rest=False,\n    num_features=10,\n    min_weight=0.01\n)\nlime_image = mark_boundaries(lime_image, lime_mask)\n\n# Display the original and LIME result\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(original_image_np)\nplt.title(f\"Original Image\\n(True: {true_class_name}, Pred: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(lime_image)\nplt.title(f\"LIME Explanation\\n(Predicted: {predicted_class_name})\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T18:29:44.529289Z","iopub.execute_input":"2025-08-21T18:29:44.529934Z","iopub.status.idle":"2025-08-21T18:29:46.301607Z","shell.execute_reply.started":"2025-08-21T18:29:44.529910Z","shell.execute_reply":"2025-08-21T18:29:46.300720Z"}},"outputs":[],"execution_count":null}]}